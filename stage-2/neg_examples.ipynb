{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read brand names into a list\n",
    "brand_file = open('brands.txt', 'r')\n",
    "brands = brand_file.readlines()\n",
    "\n",
    "for i in range(0, len(brands)):\n",
    "    brands[i] = brands[i][:-1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8547 2466\n"
     ]
    }
   ],
   "source": [
    "# extracting possible negative examples from training documents\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import random\n",
    "\n",
    "file_path = 'selected_texts/labelled_training_texts/'\n",
    "files = glob.glob(file_path + '*.txt')\n",
    "\n",
    "output1 = []\n",
    "output2 = []\n",
    "\n",
    "for file in files:\n",
    "    with open(file,'r') as f:\n",
    "        text = f.read()\n",
    "        words = text.split()\n",
    "\n",
    "        start_index = [0]\n",
    "        end_index = []\n",
    "\n",
    "        for m in re.finditer('<p>(.+?)</>',text):\n",
    "            end_index.append(m.start())\n",
    "            start_index.append(m.end())\n",
    "\n",
    "        end_index.append(len(text))\n",
    "\n",
    "        text_fragments = []\n",
    "        \n",
    "        for i in range(0, len(start_index)):\n",
    "            text_fragments.append(text[start_index[i] : end_index[i]])\n",
    "\n",
    "        candidates = []\n",
    "        n = 8\n",
    "            \n",
    "        for i, fragment in enumerate(text_fragments):\n",
    "            fragment = fragment.split()\n",
    "\n",
    "            for start in range(0, len(fragment)):\n",
    "                for length in range(2, 8):\n",
    "                    if (start + length) <= len(fragment):\n",
    "                        candidate_string = fragment[start : start + length]\n",
    "                        candidate_string = ' '.join(s for s in candidate_string)\n",
    "\n",
    "                        before = text.find(candidate_string)\n",
    "                        after = before + len(candidate_string)\n",
    "\n",
    "                        text_before = text[:before].split()\n",
    "                        text_after = text[after:].split()\n",
    "\n",
    "                        for t in range(0, len(text_before)):\n",
    "                            text_before[t] = text_before[t].replace('<p>', '')\n",
    "                            text_before[t] = text_before[t].replace('</>', '')\n",
    "\n",
    "                        for t in range(0, len(text_after)):\n",
    "                            text_after[t] = text_after[t].replace('<p>', '')\n",
    "                            text_after[t] = text_after[t].replace('</>', '')\n",
    "\n",
    "                        candidate_up = ' '.join(s for s in text_before[-n:])\n",
    "                        candidate_down = ' '.join(s for s in text_after[:n])\n",
    "                        candidate_follow = candidate_string[-1:]\n",
    "\n",
    "                        candidates.append([candidate_string, candidate_up, candidate_down, candidate_follow])\n",
    "                        \n",
    "        negative_examples_1 = []\n",
    "        negative_examples_2 = []\n",
    "\n",
    "        for candidate in candidates:\n",
    "            candidate_string = candidate[0]\n",
    "            words = candidate_string.split()\n",
    "\n",
    "            # criterion 1: Are more than half of the words capitalized?\n",
    "            capitalized = False\n",
    "            found = 0\n",
    "            for word in words:\n",
    "                if word.isalpha() and word[0].isupper():\n",
    "                    found += 1\n",
    "            \n",
    "            if found / len(words) >= 0.5:\n",
    "                capitalized = True\n",
    "\n",
    "            # criterion 2: Does the string starts with a brand name?\n",
    "            start_with_brand = False\n",
    "            found = False\n",
    "            for brand in brands:\n",
    "                if words[0].lower() == brand.lower():\n",
    "                    found = True\n",
    "                    break\n",
    "            \n",
    "            if found:\n",
    "                start_with_brand = True\n",
    "                \n",
    "            # criterion 3: Does the string ends with a number or a word with alphanumeric characters delimited by '-'?\n",
    "            found = False\n",
    "            word = words[len(words) - 1]\n",
    "            if len(re.findall('\\d+', word)) > 0 or len(re.findall('\\w+-\\w+', word)) > 0:\n",
    "                found = True\n",
    "            \n",
    "            end_with_alphanumeric = False\n",
    "            \n",
    "            if found:\n",
    "                end_with_alphanumeric = True\n",
    "                \n",
    "            if capitalized and start_with_brand:\n",
    "                if not end_with_alphanumeric:\n",
    "                    negative_examples_1.append(candidate)\n",
    "                else:\n",
    "                    negative_examples_2.append(candidate)\n",
    "            \n",
    "    output1.extend(negative_examples_1)\n",
    "    output2.extend(negative_examples_2)\n",
    "\n",
    "print(len(output1), len(output2))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11013\n"
     ]
    }
   ],
   "source": [
    "output = output1 + output2\n",
    "print(len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomly sample negative examples\n",
    "t = 2000\n",
    "neg_examples = random.sample(output, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# partial product names as potential negative examples\n",
    "special_examples = []\n",
    "n = 8\n",
    "\n",
    "for file in files:\n",
    "    with open(file,'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "        for m in re.finditer('<p>(.+?)</>',text):\n",
    "            name_start = m.start()\n",
    "            name_end = m.end()\n",
    "            before_name = text[:name_start]\n",
    "            after_name = text[name_end:]\n",
    "            \n",
    "            before_name = before_name.replace('<p>', '')\n",
    "            before_name = before_name.replace('</>', '')\n",
    "            after_name = after_name.replace('<p>', '')\n",
    "            after_name = after_name.replace('</>', '')\n",
    "            \n",
    "            words = text[name_start + 3 : name_end - 3].split()\n",
    "            words_before = before_name.split()\n",
    "            words_after = after_name.split()\n",
    "            \n",
    "            for length in range(2, len(words)):\n",
    "                candidate_string = words[:length]\n",
    "                candidate_string = ' '.join(s for s in candidate_string)\n",
    "                \n",
    "                candidate_up = words_before[-n:]\n",
    "                candidate_down = words[length:] + words_after[: n - (len(words) - length)]\n",
    "                candidate_up = ' '.join(s for s in candidate_up)\n",
    "                candidate_down = ' '.join(s for s in candidate_down)\n",
    "                candidate_follow = candidate_string[-1:]\n",
    "                \n",
    "                special_examples.append([candidate_string, candidate_up, candidate_down, candidate_follow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3329\n"
     ]
    }
   ],
   "source": [
    "print(len(special_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomly sample negative examples\n",
    "t = 2500\n",
    "special_neg_examples = random.sample(special_examples, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "# pool negative examples from different sources into a full table\n",
    "total_neg_examples = neg_examples + special_neg_examples\n",
    "print(len(total_neg_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean up the negative examples by removing punctuations at the end of the string\n",
    "for example in total_neg_examples:\n",
    "    string = example[0]\n",
    "    length = len(string)\n",
    "    \n",
    "    if string[length - 1] in [',', '.',';']:\n",
    "        example[3] = string[length - 1]\n",
    "        example[0] = string[:-1]\n",
    "    \n",
    "    elif string[-2:] == '\\'s':\n",
    "        example[3] = '\\''\n",
    "        example[0] = string[:-2]\n",
    "\n",
    "# shuffle the negative examples\n",
    "random.shuffle(total_neg_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate feature vectors from negative examples\n",
    "import csv\n",
    "\n",
    "csv_f = open('neg_feat_vec.csv', 'w')\n",
    "\n",
    "# header of the table\n",
    "fields = ['product_name','num_of_words', 'total_str_len', 'avg_word_len', 'fraction_capitalized', 'num_of_non-Eng_words', 'num_of_digits', 'word(s)_with_uppercase_letters', 'starts_with_brand', 'paranthesis', ')_in_last_word', \n",
    "          '\\w-\\w_end', '\\w-\\w_second', '\\d_end', 'contains_year', 'contains_inch_info', 'contains_core_info', 'starts_with_i', 'concatenated_words', 'keywords_downstream', \n",
    "          'is_was_downstream', '(_downstream', '$_downstream', 'the_upstream', ',_or_._after_string', '\\w-\\w_downstream', 'label']\n",
    "writer = csv.writer(csv_f, delimiter = ',')\n",
    "writer.writerow(fields)\n",
    "\n",
    "fvs = []\n",
    "\n",
    "for example in total_neg_examples:\n",
    "    product_name = example[0]\n",
    "    inst_up = example[1].split(' ')\n",
    "    inst_down = example[2].split(' ')\n",
    "    inst_follow = example[3]\n",
    "    \n",
    "    # add product name at the front\n",
    "    vector = []\n",
    "    vector.append(product_name)\n",
    "\n",
    "    # feature 1(a): number of words\n",
    "    # feature 1(b): total number of characters in the string (excluding blank space)\n",
    "    # feature 1(c): average word length\n",
    "    words = product_name.split()\n",
    "    vector.append(len(words))\n",
    "    \n",
    "    total_len = 0\n",
    "    \n",
    "    for word in words:\n",
    "        total_len += len(word)\n",
    "    \n",
    "    vector.append(total_len)\n",
    "    vector.append(total_len / len(words))\n",
    "\n",
    "    # feature 2: What is the fraction of capitalized words?\n",
    "    # feature 3: How many words are not English words?\n",
    "    upper = 0\n",
    "    total = 0\n",
    "    \n",
    "    for word in words:\n",
    "        if word.isalpha():\n",
    "            total += 1\n",
    "            if word[0].isupper():\n",
    "                upper += 1\n",
    "    \n",
    "    vector.append(upper / total)\n",
    "    vector.append(len(words) - total)\n",
    "\n",
    "    # feature 4: How many digits are in the string?\n",
    "    found = 0\n",
    "    for word in words:\n",
    "        for char in word:\n",
    "            if char.isdigit():\n",
    "                found += 1\n",
    "\n",
    "    vector.append(found)\n",
    "\n",
    "    # feature 5: Is there a word whose characters are all capitalized (excluding the leading word)?\n",
    "    found = False\n",
    "    for word in words[1:]:      # skip 1st word\n",
    "        if word.isalpha() and word.isupper():\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if found:\n",
    "        vector.append('1')\n",
    "    else:\n",
    "        vector.append('0')\n",
    "\n",
    "    # feature 6: Does the string start with a brand name, and the brand name only appears once?\n",
    "    found = False\n",
    "    \n",
    "    if words[0].lower() in brands:\n",
    "        found = True\n",
    "    \n",
    "    for word in words[1:]:\n",
    "        if word.lower() in brands:\n",
    "            found = False\n",
    "    \n",
    "    if found:\n",
    "        vector.append('1')\n",
    "    else:\n",
    "        vector.append('0')\n",
    "\n",
    "    # feature 7(a): Does the string contain '(' and ')'?\n",
    "    # feature 7(b): Does ')' appear in the last word as the last character?\n",
    "    found1 = False\n",
    "    found2 = False\n",
    "    pos = -1\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        if '(' in word:\n",
    "            found1 = True\n",
    "        if ')' in word:\n",
    "            found2 = True\n",
    "\n",
    "    if found1 and found2:\n",
    "        vector.append('1')\n",
    "    else:\n",
    "        vector.append('0')\n",
    "    \n",
    "    last_word = words[len(words) - 1]\n",
    "    \n",
    "    if last_word[-1:] == ')':\n",
    "        vector.append('1')\n",
    "    else:\n",
    "        vector.append('0')\n",
    "\n",
    "    # feature 8(a): Does the last word contain a string of alphanumeric characters delimited by '-' ?\n",
    "    # feature 8(b): Does the second word contain a string of alphanumeric characters delimited by '-'?\n",
    "    # feature 8(c): Does the last word contain a number?\n",
    "    found1 = False\n",
    "    found2 = False\n",
    "    found3 = False\n",
    "    \n",
    "    if len(re.findall('\\w+-\\w+', words[len(words) - 1])) > 0:\n",
    "        found1 = True\n",
    "    \n",
    "    if len(re.findall('\\w+-\\w+', words[1])) > 0:\n",
    "        found2 = True\n",
    "    \n",
    "    if len(re.findall('\\d+', words[len(words) - 1])) > 0:\n",
    "        found3 = True\n",
    "\n",
    "    if found1:\n",
    "        vector.append('1')\n",
    "    else:\n",
    "        vector.append('0')\n",
    "    \n",
    "    if found2:\n",
    "        vector.append('1')\n",
    "    else:\n",
    "        vector.append('0')\n",
    "        \n",
    "    if found3:\n",
    "        vector.append('1')\n",
    "    else:\n",
    "        vector.append('0')\n",
    "\n",
    "    # feature 9: Does any word contain a year?\n",
    "    found = False\n",
    "    for word in words:\n",
    "        if len(re.findall('20[0-1][0-7]', word)) > 0:\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if found:\n",
    "        vector.append('1')\n",
    "    else:\n",
    "        vector.append('0')\n",
    "\n",
    "    # feature 10: Does the string contain information on \"inches\"?\n",
    "    found = False\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if ('inch' in word.lower()) or ('inches' in word.lower()) or ('\"' in word.lower()):\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if found:\n",
    "        vector.append('1')\n",
    "    else:\n",
    "        vector.append('0')\n",
    "\n",
    "    # feature 11: Does the string contain information on \"core\"?\n",
    "    found = False\n",
    "    for word in words:\n",
    "        if 'core' in word.lower():\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if found:\n",
    "        vector.append('1')\n",
    "    else:\n",
    "        vector.append('0')\n",
    "\n",
    "    # feature 12: Is there a word that starts with 'i'?\n",
    "    found = False\n",
    "    for word in words:\n",
    "        if word.startswith('i'):\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if found:\n",
    "        vector.append('1')\n",
    "    else:\n",
    "        vector.append('0')\n",
    "\n",
    "    # feature 13: Are there two capitalized words concatenated into one word?\n",
    "    found = False\n",
    "    for word in words:\n",
    "        if (len(re.findall('[A-Z][a-z]+', word))) > 1:\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if found:\n",
    "        vector.append('1')\n",
    "    else:\n",
    "        vector.append('0')\n",
    "\n",
    "    # feature 14: Is there a keyword immediately downstream?\n",
    "    found = False\n",
    "    for word in inst_down:\n",
    "        word = word.lower()\n",
    "        if word.find('laptop') != -1 or word.find('desktop') != -1 or word.find('tablet') != -1 or word.find('notebook') != -1:\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if found:\n",
    "        vector.append('1')\n",
    "    else:\n",
    "        vector.append('0')\n",
    "\n",
    "    # feature 15: Does 'is' or 'was' occur immediately downstream?\n",
    "    found = False\n",
    "    for word in inst_down[:2]:\n",
    "        if word.lower() in ['is', 'was', 'has', 'and']:\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if found:\n",
    "        vector.append('1')\n",
    "    else:\n",
    "        vector.append('0')\n",
    "\n",
    "    # feature 16: Does '(' and/or ')' occur immediately downstream?\n",
    "    found = False\n",
    "    for word in inst_down[:2]:\n",
    "        if '(' in word.lower():\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if found:\n",
    "        vector.append('1')\n",
    "    else:\n",
    "        vector.append('0')\n",
    "\n",
    "    # feature 17: Does '$' occur immediately downstream?\n",
    "    found = False\n",
    "    for word in inst_down[0:1]:\n",
    "        if '$' in word.lower():\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if found:\n",
    "        vector.append('1')\n",
    "    else:\n",
    "        vector.append('0')\n",
    "\n",
    "    # feature 18: Does 'the' occur immediately upstream?\n",
    "    found = False\n",
    "    for word in inst_up[-2:]:\n",
    "        if word.lower() == 'the':\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if found:\n",
    "        vector.append('1')\n",
    "    else:\n",
    "        vector.append('0')\n",
    "\n",
    "    # feature 19: Does ',' or '.' occur immediately after the string?\n",
    "    found = False\n",
    "    if (inst_follow == ',') or (inst_follow == '.'):\n",
    "        found = True\n",
    "\n",
    "    if found:\n",
    "        vector.append('1')\n",
    "    else:\n",
    "        vector.append('0')\n",
    "    \n",
    "    # feature 20: Does a word containing alphanumerical characters delimited by '-' occur right after the string?\n",
    "    found = False\n",
    "    for word in inst_down[0:1]:\n",
    "        if len(re.findall('\\w+-\\w+', word)) > 0:\n",
    "            found = True\n",
    "            break\n",
    "    \n",
    "    if found:\n",
    "        vector.append('1')\n",
    "    else:\n",
    "        vector.append('0')\n",
    "    \n",
    "    vector.append('0')\n",
    "\n",
    "    writer.writerow(vector)   \n",
    "    fvs.append(vector)\n",
    "\n",
    "csv_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
