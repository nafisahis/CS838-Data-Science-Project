{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Matching Workflow - 31st March 2017\n",
    "\n",
    "This notebook contains EM steps that has been done on songs using py_entitymatching. Our goal is to come up with a workflow to match songs from the datasets from a research lab from Silicon Valley. Specifically, we want Precision as 90% and Recall as high as possible. The datasets contain information about the songs.\n",
    "\n",
    "First, we need to import py_entitymatching package and other libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import py_entitymatching as em\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_A = os.path.join('..','dataset','datasets','tracks.csv')\n",
    "path_B = os.path.join('..','dataset','datasets','songs.csv')\n",
    "\n",
    "# Read the CSV files\n",
    "A = em.read_csv_metadata(path_A,low_memory=False) # setting the parameter low_memory to False  to speed up loading.\n",
    "B = em.read_csv_metadata(path_B,low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down sampling tabels\n",
    "\n",
    "Two smaller datasets, track_sample.csv and songs_sample.csv, are produced by down sampling the full datasets. They contain 8592 and 10000 tuples, respectively. \n",
    "\n",
    "To avoid case-sensitive string matching, we also changed the entire tables to lowercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Down sample the tables\n",
    "sample_A, sample_B = em.down_sample(A, B, size=10000, y_param=1, show_progress=False)\n",
    "\n",
    "# Set 'ID as the keys to the input tables\n",
    "em.set_key(sample_A,'id')\n",
    "em.set_key(sample_B,'id')\n",
    "\n",
    "sample_A = sample_A.apply(lambda x: x.astype(str).str.lower())\n",
    "sample_B = sample_B.apply(lambda x: x.astype(str).str.lower())\n",
    "\n",
    "#Print lengths of the sampled tables\n",
    "print(len(sample_A))\n",
    "print(len(sample_B))\n",
    "\n",
    "#saving the down sampled datasets\n",
    "sample_A.to_csv('tracks_sample.csv', index = False, sep = ',')\n",
    "sample_B.to_csv('songs_sample.csv', index = False, sep = ',')\n",
    "\n",
    "#Get headers of sampled tables\n",
    "headers_A = list(A.columns)\n",
    "headers_B = list(B.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying blocker on down sampled datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do the matching, we would like to remove the obviously non-matching tuple pairs from the down sampled tables. This would reduce the number of tuple pairs considered for matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that two songs with different artist names and vice versa will not match. So we decide to apply blocking over song title and artist name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "block_f = em.get_features_for_blocking(sample_A, sample_B)\n",
    "\n",
    "path_A = 'tracks_sample.csv'\n",
    "path_B = 'songs_sample.csv'\n",
    "\n",
    "# Read the CSV files\n",
    "sample_A = em.read_csv_metadata(path_A,key='id',low_memory=False)\n",
    "sample_B = em.read_csv_metadata(path_B,key='id',low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three rules were applied in a sequence to remove tuple pairs that are unlikely to match.\n",
    "\n",
    "**1)\tPairs whose song names have a jaccard score (3-grams) lower than 0.1 were removed.**\n",
    "\n",
    "**2)\tPairs whose song names have less than 25% common words were removed. **\n",
    "\n",
    "**3)\tPairs whose artists have less than 25% common words were removed. **\n",
    "\n",
    "Two helper functions ***title_function*** and ***artists_function***, defined above, were used to filter out tuples according to these rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def title_function(x, y):\n",
    "\n",
    "    x_title = str(x['song_title'])\n",
    "    y_title = str(y['song_title'])\n",
    "    \n",
    "    if (x_title in y_title) or (y_title in x_title):\n",
    "        return False\n",
    "    else:\n",
    "        x_split = x_title.split()\n",
    "        y_split = y_title.split()\n",
    "        \n",
    "        intersection = len(set(x_split) & set(y_split))\n",
    "        union = len(set(x_split) | set(y_split))\n",
    "        \n",
    "        if(intersection / union < 0.25):\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def artists_function(x, y):\n",
    "\n",
    "    x_artists = str(x['artists'])\n",
    "    y_artists = str(y['artists'])\n",
    "    \n",
    "    if (x_artists in y_artists) or (y_artists in x_artists):\n",
    "        return False\n",
    "    else:\n",
    "        x_split = x_artists.split()\n",
    "        y_split = y_artists.split()\n",
    "        \n",
    "        intersection = len(set(x_split) & set(y_split))\n",
    "        union = len(set(x_split) | set(y_split))\n",
    "        \n",
    "        if(intersection / union < 0.25):\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rb = em.RuleBasedBlocker()\n",
    "ob = em.OverlapBlocker()\n",
    "bb = em.BlackBoxBlocker()\n",
    "\n",
    "# remove pairs that don't share similar titles\n",
    "rule1 = ['song_title_song_title_jac_qgm_3_qgm_3(ltuple, rtuple) < 0.1']\n",
    "rb.add_rule(rule1, block_f)\n",
    "\n",
    "C1 = rb.block_tables(sample_A, sample_B, l_output_attrs=['song_title','year','artists'], r_output_attrs=['song_title','year','artists'], show_progress=False)\n",
    "\n",
    "bb.set_black_box_function(title_function)\n",
    "C2 = bb.block_candset(C1)\n",
    "\n",
    "bb.set_black_box_function(artists_function)\n",
    "C3 = bb.block_candset(C2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(C3))\n",
    "C3.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging the blocker output\n",
    "\n",
    "By using the debugging tool supplied by Magellan, we examined the tuple pairs that had been blocked has very few wrongly removed actual matches. In addtion, we confirmed by examining the tuple pairs that survived blocking that we ended up with a reasonale number of positive examples and negative examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'em' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-428507275af4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# debug the blocker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdbg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug_blocker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_A\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_B\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'em' is not defined"
     ]
    }
   ],
   "source": [
    "# debug the blocker\n",
    "dbg = em.debug_blocker(C2, sample_A, sample_B, output_size=50)\n",
    "dbg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling and labeling the candidate set\n",
    "\n",
    "First, we randomly sample 400 tuple pairs for labeling purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sample the result set C6\n",
    "S= em.sample_table(C3,400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we labelled the sampled candidate set based on the following criteria.\n",
    "\n",
    "1. *if two tuples has the same song name (excluding version information)*\n",
    "    \n",
    "    * if they share common artists\t                 **MATCH**\n",
    "    * else\t\t\t\t                                     **MISMATCH**\n",
    "\n",
    "2. *else\t\t\t\t**MISMATCH***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label the sampled data\n",
    "G = em.label_table(S, label_column_name='gold_labels')\n",
    "\n",
    "G.to_csv('labeled_data.csv', index = False, sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching tuple pairs in the candidate set\n",
    "\n",
    "In this step, we would want to match the tuple pairs in the candidate set. Specifically, we use learning-based method for matching purposes. This typically involves the following five steps:\n",
    "\n",
    "1. Splitting the labeled data into development and evaluation set\n",
    "2. Selecting the best learning based matcher using the development set\n",
    "3. Evaluating the selected matcher using the evaluation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the labeled data into development and evaluation set\n",
    "\n",
    "In this step, we split the labeled data into two sets: development (I) and evaluation (J). Specifically, the development set is used to come up with the best learning-based matcher and the evaluation set used to evaluate the selected matcher on unseen data. Size of each set is 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split G into I an J\n",
    "train_test = em.split_train_test(G, train_proportion=0.5,random_state=0)\n",
    "I = train_test['train']\n",
    "J = train_test['test']\n",
    "\n",
    "I.to_csv('train.csv')\n",
    "J.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the best learning-based matcher\n",
    "\n",
    "Selecting the best learning-based matcher typically involves the following steps:\n",
    "\n",
    "\n",
    "1. Creating features\n",
    "2. Converting the development set into feature vectors\n",
    "3. Creating a set of learning-based matchers\n",
    "4. Selecting the best learning-based matcher using k-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating features\n",
    "\n",
    "Next, we need to create a set of features for the development set. Using automatic feature generation in py_entitymatching, set of features F is generated based on the attributes in the input tables. \n",
    "\n",
    "We removed features that take ‘id’ as parameter from F as it does not contribute effectively to decide the matching between the tuple pairs in A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a set of features\n",
    "F = em.get_features_for_matching(A, B)\n",
    "print(F.feature_name)\n",
    "\n",
    "# Remove all features on id parameters\n",
    "F = F[4:]\n",
    "\n",
    "# Remove some features on year parameter\n",
    "F = F.drop(F.index[[0,1,2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the development set to feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert I into a set of feature vectors using F\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F, \n",
    "                            attrs_after='gold_labels',\n",
    "                            show_progress=False) \n",
    "\n",
    "# Display first few rows\n",
    "H.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing value handling\n",
    "\n",
    "We imputed missing values for feature vectors with 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if the feature vectors contain missing values\n",
    "# A return value of True means that there are missing values\n",
    "any(pd.notnull(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Impute feature vectors with the mean of the column values.\n",
    "H.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a set of learning-based matchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a set of ML-matchers\n",
    "dt = em.DTMatcher(name='DecisionTree', random_state=0,max_depth=5)\n",
    "svm = em.SVMMatcher(name='SVM', random_state=0)\n",
    "rf = em.RFMatcher(name='RF', random_state=0)\n",
    "lg = em.LogRegMatcher(name='LogReg', random_state=0)\n",
    "ln = em.LinRegMatcher(name='LinReg')\n",
    "nb = em.NBMatcher(name='NaiveBayes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting the best matcher using cross-validation\n",
    "\n",
    "Now, we select the best matcher using 5-fold cross-validation. We used 'precision' and 'recall' metric and found **Random Forest (X)** as the best matcher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute accuracy and select the best ML matcher using CV\n",
    "result_precision = em.select_matcher([dt, rf, svm, ln, lg, nb], table=H, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        k=5,\n",
    "        target_attr='gold_labels', metric='precision', random_state=0)\n",
    "result_recall = em.select_matcher([dt, rf, svm, ln, lg, nb], table=H, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        k=5,\n",
    "        target_attr='gold_labels', metric='recall', random_state=0)\n",
    "result_f1 = em.select_matcher([dt, rf, svm, ln, lg, nb], table=H, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        k=5,\n",
    "        target_attr='gold_labels', metric='f1', random_state=0)\n",
    "result_precision['cv_stats']\n",
    "result_recall['cv_stats']\n",
    "result_f1['cv_stats']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debugging matcher\n",
    "\n",
    "To further improve the accuracy of X, we debugged it. To do so, first H was split into sets P and Q."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Debug Random Forest Matcher X\n",
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Debug X using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        target_attr='gold_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On examining the false positives, 2 of the 3 false positives generated were due to an exact match in either song_title or artists between the tuples. \n",
    "We tried with different subsets of the feature set involving these parameters to remove redundancy and improve its accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Debugging iteration 1 - remove song_title_song_title_lev_dist, song_title_song_title_nmw and song_title_song_title_sw,\n",
    "#song_title_song_title_cos_dlm_dc0_dlm_dc0, song_title_song_title_mel,song_title_song_title_jac_dlm_dc0_dlm_dc0\n",
    "F = F.drop(F.index[[2,3,4,5,7,8]])\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F, \n",
    "                            attrs_after='gold_labels',\n",
    "                            show_progress=False) \n",
    "# Impute feature vectors with 0.\n",
    "H.fillna(value=0, inplace=True)\n",
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']\n",
    "# Debug the matcher using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        target_attr='gold_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Debugging iteration 2 - remove song_title_song_title_lev_sim\n",
    "F = F.drop(F.index[[2]])\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F, \n",
    "                            attrs_after='gold_labels',\n",
    "                            show_progress=False) \n",
    "# Impute feature vectors with 0.\n",
    "H.fillna(value=0, inplace=True)\n",
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']\n",
    "# Debug the matcher using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        target_attr='gold_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Debugging iteration 3 - remove artists_artists_lev_dist, artists_artists_nmw,artists_artists_sw\n",
    "F = F.drop(F.index[[3,4,5,6,8,9]])\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F, \n",
    "                            attrs_after='gold_labels',\n",
    "                            show_progress=False) \n",
    "# Impute feature vectors with 0.\n",
    "H.fillna(value=0, inplace=True)\n",
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']\n",
    "# Debug the matcher using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        target_attr='gold_labels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Debugging iteration 4 - remove artists_artists_lev_sim\n",
    "F = F.drop(F.index[[3]])\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F, \n",
    "                            attrs_after='gold_labels',\n",
    "                            show_progress=False) \n",
    "# Impute feature vectors with 0.\n",
    "H.fillna(value=0, inplace=True)\n",
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']\n",
    "# Debug the matcher using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        target_attr='gold_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Debugging iteration 5 - add feature product of jaccard measure on song_title and artists\n",
    "H['song_title_song_title_jac_qgm_3_qgm_3']\n",
    "H['artists_artists_jac_qgm_3_qgm_3']\n",
    "H['song_title_artists_score']= H.song_title_song_title_jac_qgm_3_qgm_3*H.artists_artists_jac_qgm_3_qgm_3\n",
    "# Impute feature vectors with 0.\n",
    "H.fillna(value=0, inplace=True)\n",
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']\n",
    "# Debug RF matcher using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        target_attr='gold_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the score of precision dropped in all cases, we proceed with matcher X as the best matcher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the matching output\n",
    "\n",
    "Evaluating the matching outputs for the evaluation set typically involves the following four steps:\n",
    "\n",
    "1. Converting the evaluation set to feature vectors\n",
    "2. Training matcher using the feature vectors extracted from the development set\n",
    "3. Predicting the evaluation set using the trained matcher\n",
    "4. Evaluating the predicted matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the evaluation set to feature vectors\n",
    "\n",
    "As before, we convert to the feature vectors (using the feature table and the evaluation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate matching output\n",
    "# Convert J into a set of feature vectors using feature table\n",
    "L = em.extract_feature_vecs(J, feature_table=F,\n",
    "                            attrs_after='gold_labels', show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if the feature vectors contain missing values\n",
    "# A return value of True means that there are missing values\n",
    "any(pd.notnull(L))\n",
    "L.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train using feature vectors from I using decision tree\n",
    "dt.fit(table=H, \n",
    "       exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')\n",
    "# Predict on L \n",
    "predictions = dt.predict(table=L, exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "                         append=True,target_attr='predicted_labels')\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'gold_labels', 'predicted_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train using feature vectors from I using random forest\n",
    "rf.fit(table=H, \n",
    "       exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')\n",
    "# Predict on L \n",
    "predictions = rf.predict(table=L, exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "                         append=True,target_attr='predicted_labels')\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'gold_labels', 'predicted_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
