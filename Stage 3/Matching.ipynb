{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import py_entitymatching as em\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets_dir = em.get_install_path() + os.sep + 'datasets'\n",
    "path_A = datasets_dir + os.sep + 'tracks_sample.csv'\n",
    "path_B = datasets_dir + os.sep + 'songs_sample.csv'\n",
    "path_G = datasets_dir + os.sep + 'labeled_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV files\n",
    "A = em.read_csv_metadata(path_A,key='id', low_memory=False) # setting the parameter low_memory to False  to speed up loading.\n",
    "B = em.read_csv_metadata(path_B,key='id',low_memory=False)\n",
    "G = em.read_csv_metadata(path_G,key='id',low_memory=False,ltable=A, rtable=B, \n",
    "                         fk_ltable='ltable_id', fk_rtable='rtable_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split G into I an J\n",
    "train_test = em.split_train_test(G, train_proportion=0.5,random_state=0)\n",
    "I = train_test['train']\n",
    "J = train_test['test']\n",
    "I.to_csv('train.csv')\n",
    "J.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                     id_id_exm\n",
      "1                                     id_id_anm\n",
      "2                                id_id_lev_dist\n",
      "3                                 id_id_lev_sim\n",
      "4                                 year_year_exm\n",
      "5                                 year_year_anm\n",
      "6                            year_year_lev_dist\n",
      "7                             year_year_lev_sim\n",
      "8         song_title_song_title_jac_qgm_3_qgm_3\n",
      "9     song_title_song_title_cos_dlm_dc0_dlm_dc0\n",
      "10    song_title_song_title_jac_dlm_dc0_dlm_dc0\n",
      "11                    song_title_song_title_mel\n",
      "12               song_title_song_title_lev_dist\n",
      "13                song_title_song_title_lev_sim\n",
      "14                    song_title_song_title_nmw\n",
      "15                     song_title_song_title_sw\n",
      "16              artists_artists_jac_qgm_3_qgm_3\n",
      "17          artists_artists_cos_dlm_dc0_dlm_dc0\n",
      "18          artists_artists_jac_dlm_dc0_dlm_dc0\n",
      "19                          artists_artists_mel\n",
      "20                     artists_artists_lev_dist\n",
      "21                      artists_artists_lev_sim\n",
      "22                          artists_artists_nmw\n",
      "23                           artists_artists_sw\n",
      "Name: feature_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Generate a set of features\n",
    "F = em.get_features_for_matching(A, B)\n",
    "print(F.feature_name)\n",
    "# Remove all features on id parameters\n",
    "F = F[4:]\n",
    "# Remove some features on year parameter\n",
    "F = F.drop(F.index[[0,1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert I into a set of feature vectors using F\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F, \n",
    "                            attrs_after='gold_labels',\n",
    "                            show_progress=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the feature vectors contain missing values\n",
    "# A return value of True means that there are missing values\n",
    "any(pd.notnull(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Impute feature vectors with 0.\n",
    "H.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a set of ML-matchers\n",
    "dt = em.DTMatcher(name='DecisionTree', random_state=0,max_depth=5)\n",
    "svm = em.SVMMatcher(name='SVM', random_state=0)\n",
    "rf = em.RFMatcher(name='RF', random_state=0)\n",
    "lg = em.LogRegMatcher(name='LogReg', random_state=0)\n",
    "ln = em.LinRegMatcher(name='LinReg')\n",
    "nb = em.NBMatcher(name='NaiveBayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Num folds</th>\n",
       "      <th>Fold 1</th>\n",
       "      <th>Fold 2</th>\n",
       "      <th>Fold 3</th>\n",
       "      <th>Fold 4</th>\n",
       "      <th>Fold 5</th>\n",
       "      <th>Mean score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>&lt;py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x0000019E27671358&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.926108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>&lt;py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x0000019E27671240&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>&lt;py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x0000019E27671160&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.762289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x0000019E27671278&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.929450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x0000019E27671080&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.939540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>&lt;py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x0000019E27671198&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  \\\n",
       "0  DecisionTree   \n",
       "1            RF   \n",
       "2           SVM   \n",
       "3        LinReg   \n",
       "4        LogReg   \n",
       "5    NaiveBayes   \n",
       "\n",
       "                                                                                Matcher  \\\n",
       "0          <py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x0000019E27671358>   \n",
       "1          <py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x0000019E27671240>   \n",
       "2        <py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x0000019E27671160>   \n",
       "3  <py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x0000019E27671278>   \n",
       "4  <py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x0000019E27671080>   \n",
       "5          <py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x0000019E27671198>   \n",
       "\n",
       "   Num folds    Fold 1    Fold 2    Fold 3    Fold 4    Fold 5  Mean score  \n",
       "0          5  0.833333  0.958333  1.000000  0.956522  0.882353    0.926108  \n",
       "1          5  0.888889  0.920000  1.000000  0.958333  1.000000    0.953444  \n",
       "2          5  0.607143  0.821429  0.870968  0.833333  0.678571    0.762289  \n",
       "3          5  0.850000  0.920000  0.964286  0.962963  0.950000    0.929450  \n",
       "4          5  0.850000  0.916667  0.931034  1.000000  1.000000    0.939540  \n",
       "5          5  0.888889  0.920000  0.962963  0.923077  1.000000    0.938986  "
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute precision and select the best ML matcher using CV\n",
    "result_precision = em.select_matcher([dt, rf, svm, ln, lg, nb], table=H, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        k=5,\n",
    "        target_attr='gold_labels', metric='precision', random_state=0)\n",
    "\n",
    "result_precision['cv_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Num folds</th>\n",
       "      <th>Fold 1</th>\n",
       "      <th>Fold 2</th>\n",
       "      <th>Fold 3</th>\n",
       "      <th>Fold 4</th>\n",
       "      <th>Fold 5</th>\n",
       "      <th>Mean score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>&lt;py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x0000019E27671358&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.888781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>&lt;py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x0000019E27671240&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.932410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>&lt;py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x0000019E27671160&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x0000019E27671278&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x0000019E27671080&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>&lt;py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x0000019E27671198&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.954917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  \\\n",
       "0  DecisionTree   \n",
       "1            RF   \n",
       "2           SVM   \n",
       "3        LinReg   \n",
       "4        LogReg   \n",
       "5    NaiveBayes   \n",
       "\n",
       "                                                                                Matcher  \\\n",
       "0          <py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x0000019E27671358>   \n",
       "1          <py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x0000019E27671240>   \n",
       "2        <py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x0000019E27671160>   \n",
       "3  <py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x0000019E27671278>   \n",
       "4  <py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x0000019E27671080>   \n",
       "5          <py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x0000019E27671198>   \n",
       "\n",
       "   Num folds    Fold 1    Fold 2    Fold 3    Fold 4    Fold 5  Mean score  \n",
       "0          5  0.882353  1.000000  0.925926  0.846154  0.789474    0.888781  \n",
       "1          5  0.941176  1.000000  0.888889  0.884615  0.947368    0.932410  \n",
       "2          5  1.000000  1.000000  1.000000  0.961538  1.000000    0.992308  \n",
       "3          5  1.000000  1.000000  1.000000  1.000000  1.000000    1.000000  \n",
       "4          5  1.000000  0.956522  1.000000  0.961538  1.000000    0.983612  \n",
       "5          5  0.941176  1.000000  0.962963  0.923077  0.947368    0.954917  "
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_recall = em.select_matcher([dt, rf, svm, ln, lg, nb], table=H, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        k=5,\n",
    "        target_attr='gold_labels', metric='recall', random_state=0)\n",
    "result_recall['cv_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Num folds</th>\n",
       "      <th>Fold 1</th>\n",
       "      <th>Fold 2</th>\n",
       "      <th>Fold 3</th>\n",
       "      <th>Fold 4</th>\n",
       "      <th>Fold 5</th>\n",
       "      <th>Mean score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>&lt;py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x0000019E27671358&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.905739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>&lt;py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x0000019E27671240&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.941354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>&lt;py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x0000019E27671160&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.857984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x0000019E27671278&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.962912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x0000019E27671080&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>&lt;py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x0000019E27671198&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.946326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  \\\n",
       "0  DecisionTree   \n",
       "1            RF   \n",
       "2           SVM   \n",
       "3        LinReg   \n",
       "4        LogReg   \n",
       "5    NaiveBayes   \n",
       "\n",
       "                                                                                Matcher  \\\n",
       "0          <py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x0000019E27671358>   \n",
       "1          <py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x0000019E27671240>   \n",
       "2        <py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x0000019E27671160>   \n",
       "3  <py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x0000019E27671278>   \n",
       "4  <py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x0000019E27671080>   \n",
       "5          <py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x0000019E27671198>   \n",
       "\n",
       "   Num folds    Fold 1    Fold 2    Fold 3    Fold 4    Fold 5  Mean score  \n",
       "0          5  0.857143  0.978723  0.961538  0.897959  0.833333    0.905739  \n",
       "1          5  0.914286  0.958333  0.941176  0.920000  0.972973    0.941354  \n",
       "2          5  0.755556  0.901961  0.931034  0.892857  0.808511    0.857984  \n",
       "3          5  0.918919  0.958333  0.981818  0.981132  0.974359    0.962912  \n",
       "4          5  0.918919  0.936170  0.964286  0.980392  1.000000    0.959953  \n",
       "5          5  0.914286  0.958333  0.962963  0.923077  0.972973    0.946326  "
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_f1 = em.select_matcher([dt, rf, svm, ln, lg, nb], table=H, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        k=5,\n",
    "        target_attr='gold_labels', metric='f1', random_state=0)\n",
    "result_f1['cv_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Debug Random Forest Matcher X\n",
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Debug X using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        target_attr='gold_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Debugging iteration 1 - remove song_title_song_title_lev_dist, song_title_song_title_nmw and song_title_song_title_sw,\n",
    "#song_title_song_title_cos_dlm_dc0_dlm_dc0, song_title_song_title_mel,song_title_song_title_jac_dlm_dc0_dlm_dc0\n",
    "F_D = F\n",
    "F_D = F_D.drop(F_D.index[[2,3,4,5,7,8]])\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F_D, \n",
    "                            attrs_after='gold_labels',\n",
    "                            show_progress=False) \n",
    "# Impute feature vectors with 0.\n",
    "H.fillna(value=0, inplace=True)\n",
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']\n",
    "# Debug the matcher using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        target_attr='gold_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7                         year_year_lev_sim\n",
      "8     song_title_song_title_jac_qgm_3_qgm_3\n",
      "16          artists_artists_jac_qgm_3_qgm_3\n",
      "17      artists_artists_cos_dlm_dc0_dlm_dc0\n",
      "18      artists_artists_jac_dlm_dc0_dlm_dc0\n",
      "19                      artists_artists_mel\n",
      "20                 artists_artists_lev_dist\n",
      "21                  artists_artists_lev_sim\n",
      "22                      artists_artists_nmw\n",
      "23                       artists_artists_sw\n",
      "Name: feature_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Debugging iteration 2 - remove song_title_song_title_lev_sim\n",
    "F_D = F_D.drop(F_D.index[[2]])\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F_D, \n",
    "                            attrs_after='gold_labels',\n",
    "                            show_progress=False) \n",
    "# Impute feature vectors with 0.\n",
    "H.fillna(value=0, inplace=True)\n",
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']\n",
    "# Debug the matcher using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        target_attr='gold_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Debugging iteration 3 - remove artists_artists_lev_dist, artists_artists_nmw,artists_artists_sw\n",
    "F_D = F_D.drop(F_D.index[[3,4,5,6,8,9]])\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F_D, \n",
    "                            attrs_after='gold_labels',\n",
    "                            show_progress=False) \n",
    "# Impute feature vectors with 0.\n",
    "H.fillna(value=0, inplace=True)\n",
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']\n",
    "# Debug the matcher using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        target_attr='gold_labels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Debugging iteration 4 - remove artists_artists_lev_sim\n",
    "F_D = F_D.drop(F_D.index[[3]])\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F_D, \n",
    "                            attrs_after='gold_labels',\n",
    "                            show_progress=False) \n",
    "# Impute feature vectors with 0.\n",
    "H.fillna(value=0, inplace=True)\n",
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']\n",
    "# Debug the matcher using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        target_attr='gold_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Debugging iteration 5 - add feature product of jaccard measure on song_title and artists\n",
    "H['song_title_song_title_jac_qgm_3_qgm_3']\n",
    "H['artists_artists_jac_qgm_3_qgm_3']\n",
    "H['song_title_artists_score']= H.song_title_song_title_jac_qgm_3_qgm_3*H.artists_artists_jac_qgm_3_qgm_3\n",
    "# Impute feature vectors with 0.\n",
    "H.fillna(value=0, inplace=True)\n",
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']\n",
    "# Debug RF matcher using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        target_attr='gold_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate matching output\n",
    "# Convert J into a set of feature vectors using feature table\n",
    "L = em.extract_feature_vecs(J, feature_table=F,\n",
    "                            attrs_after='gold_labels', show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if the feature vectors contain missing values\n",
    "# A return value of True means that there are missing values\n",
    "any(pd.notnull(L))\n",
    "L.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert I into a set of feature vectors using F\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F, \n",
    "                            attrs_after='gold_labels',\n",
    "                            show_progress=False)\n",
    "# Check if the feature vectors contain missing values and change to 0\n",
    "any(pd.notnull(H))\n",
    "H.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 92.98% (106/114)\n",
      "Recall : 92.17% (106/115)\n",
      "F1 : 92.58%\n",
      "False positives : 8 (out of 114 positive predictions)\n",
      "False negatives : 9 (out of 86 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I using decision tree\n",
    "dt.fit(table=H, \n",
    "       exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')\n",
    "# Predict on L \n",
    "predictions_dt = dt.predict(table=L, exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "                         append=True,target_attr='predicted_dt_labels')\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions_dt, 'gold_labels', 'predicted_dt_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 94.55% (104/110)\n",
      "Recall : 90.43% (104/115)\n",
      "F1 : 92.44%\n",
      "False positives : 6 (out of 110 positive predictions)\n",
      "False negatives : 11 (out of 90 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I using random forest\n",
    "rf.fit(table=H, \n",
    "       exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')\n",
    "# Predict on L \n",
    "predictions_rf = rf.predict(table=L, exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels','predicted_dt_labels'], \n",
    "                         append=True,target_attr='predicted_rf_labels')\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions_rf, 'gold_labels', 'predicted_rf_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 73.86% (113/153)\n",
      "Recall : 98.26% (113/115)\n",
      "F1 : 84.33%\n",
      "False positives : 40 (out of 153 positive predictions)\n",
      "False negatives : 2 (out of 47 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I using svm\n",
    "svm.fit(table=H, \n",
    "       exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')\n",
    "# Predict on L \n",
    "predictions_svm = svm.predict(table=L, exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels','predicted_dt_labels','predicted_rf_labels'], \n",
    "                         append=True,target_attr='predicted_svm_labels')\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions_svm, 'gold_labels', 'predicted_svm_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 95.54% (107/112)\n",
      "Recall : 93.04% (107/115)\n",
      "F1 : 94.27%\n",
      "False positives : 5 (out of 112 positive predictions)\n",
      "False negatives : 8 (out of 88 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I using logistic regression\n",
    "lg.fit(table=H, \n",
    "       exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')\n",
    "# Predict on L \n",
    "predictions_lg= lg.predict(table=L, exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels','predicted_dt_labels','predicted_rf_labels','predicted_svm_labels'], \n",
    "                         append=True,target_attr='predicted_lg_labels')\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions_lg, 'gold_labels', 'predicted_lg_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 94.96% (113/119)\n",
      "Recall : 98.26% (113/115)\n",
      "F1 : 96.58%\n",
      "False positives : 6 (out of 119 positive predictions)\n",
      "False negatives : 2 (out of 81 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I using linear regression\n",
    "ln.fit(table=H, \n",
    "       exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')\n",
    "# Predict on L \n",
    "predictions_ln = ln.predict(table=L, exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels','predicted_dt_labels','predicted_rf_labels','predicted_svm_labels','predicted_lg_labels'], \n",
    "                         append=True,target_attr='predicted_ln_labels')\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions_ln, 'gold_labels', 'predicted_ln_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 95.61% (109/114)\n",
      "Recall : 94.78% (109/115)\n",
      "F1 : 95.2%\n",
      "False positives : 5 (out of 114 positive predictions)\n",
      "False negatives : 6 (out of 86 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I using naive bayes\n",
    "nb.fit(table=H, \n",
    "       exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')\n",
    "# Predict on L \n",
    "predictions_nb = nb.predict(table=L, exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels','predicted_dt_labels','predicted_rf_labels','predicted_svm_labels','predicted_lg_labels','predicted_ln_labels'], \n",
    "                         append=True,target_attr='predicted_nb_labels')\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions_nb, 'gold_labels', 'predicted_nb_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
