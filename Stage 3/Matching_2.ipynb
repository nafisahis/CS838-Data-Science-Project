{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import py_entitymatching as em\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets_dir = em.get_install_path() + os.sep + 'datasets'\n",
    "path_A = datasets_dir + os.sep + 'tracks_sample.csv'\n",
    "path_B = datasets_dir + os.sep + 'songs_sample.csv'\n",
    "path_G = datasets_dir + os.sep + 'labeled_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV files\n",
    "A = em.read_csv_metadata(path_A,key='id', low_memory=False) # setting the parameter low_memory to False  to speed up loading.\n",
    "B = em.read_csv_metadata(path_B,key='id',low_memory=False)\n",
    "G = em.read_csv_metadata(path_G,key='id',low_memory=False,ltable=A, rtable=B, \n",
    "                         fk_ltable='ltable_id', fk_rtable='rtable_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split G into I an J\n",
    "train_test = em.split_train_test(G, train_proportion=0.5,random_state=0)\n",
    "I = train_test['train']\n",
    "J = train_test['test']\n",
    "I.to_csv('train.csv')\n",
    "J.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                     id_id_exm\n",
      "1                                     id_id_anm\n",
      "2                                id_id_lev_dist\n",
      "3                                 id_id_lev_sim\n",
      "4                                 year_year_exm\n",
      "5                                 year_year_anm\n",
      "6                            year_year_lev_dist\n",
      "7                             year_year_lev_sim\n",
      "8         song_title_song_title_jac_qgm_3_qgm_3\n",
      "9     song_title_song_title_cos_dlm_dc0_dlm_dc0\n",
      "10    song_title_song_title_jac_dlm_dc0_dlm_dc0\n",
      "11                    song_title_song_title_mel\n",
      "12               song_title_song_title_lev_dist\n",
      "13                song_title_song_title_lev_sim\n",
      "14                    song_title_song_title_nmw\n",
      "15                     song_title_song_title_sw\n",
      "16              artists_artists_jac_qgm_3_qgm_3\n",
      "17          artists_artists_cos_dlm_dc0_dlm_dc0\n",
      "18          artists_artists_jac_dlm_dc0_dlm_dc0\n",
      "19                          artists_artists_mel\n",
      "20                     artists_artists_lev_dist\n",
      "21                      artists_artists_lev_sim\n",
      "22                          artists_artists_nmw\n",
      "23                           artists_artists_sw\n",
      "Name: feature_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Generate a set of features\n",
    "F = em.get_features_for_matching(A, B)\n",
    "print(F.feature_name)\n",
    "#Step 1 removing all features on id parameters\n",
    "AB = F[4:]\n",
    "#AB = F.iloc[[7,8,16]]\n",
    "#print(type(F))\n",
    "#Step 2 - removing year_year_exm, year_year_lev_dist and Step 3 removing year_year_anm\n",
    "AB = AB.drop(AB.index[[0,1,2]])\n",
    "# #Step 4 - removing song_title_song_title_lev_dist, song_title_song_title_nmw and song_title_song_title_sw\n",
    "# AB = AB.drop(AB.index[[5,7,8]])\n",
    "# #Step 5 - removing song_title_song_title_cos_dlm_dc0_dlm_dc0, song_title_song_title_mel\n",
    "# AB = AB.drop(AB.index[[2,4]])\n",
    "# #Step 6 - removing song_title_song_title_jac_dlm_dc0_dlm_dc0, song_title_song_title_lev_sim\n",
    "# AB = AB.drop(AB.index[[2,3]])\n",
    "# #Step 7 - removing artists_artists_lev_dist, artists_artists_nmw,artists_artists_sw\n",
    "# AB = AB.drop(AB.index[[3,4,5,6,8,9]])\n",
    "# #Step 8 - removing artists_artists_lev_sim\n",
    "# AB = AB.drop(AB.index[[3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7                             year_year_lev_sim\n",
       "8         song_title_song_title_jac_qgm_3_qgm_3\n",
       "9     song_title_song_title_cos_dlm_dc0_dlm_dc0\n",
       "10    song_title_song_title_jac_dlm_dc0_dlm_dc0\n",
       "11                    song_title_song_title_mel\n",
       "12               song_title_song_title_lev_dist\n",
       "13                song_title_song_title_lev_sim\n",
       "14                    song_title_song_title_nmw\n",
       "15                     song_title_song_title_sw\n",
       "16              artists_artists_jac_qgm_3_qgm_3\n",
       "17          artists_artists_cos_dlm_dc0_dlm_dc0\n",
       "18          artists_artists_jac_dlm_dc0_dlm_dc0\n",
       "19                          artists_artists_mel\n",
       "20                     artists_artists_lev_dist\n",
       "21                      artists_artists_lev_sim\n",
       "22                          artists_artists_nmw\n",
       "23                           artists_artists_sw\n",
       "Name: feature_name, dtype: object"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AB.feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the I into a set of feature vectors using F\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=AB, \n",
    "                            attrs_after='gold_labels',\n",
    "                            show_progress=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the feature vectors contain missing values\n",
    "# A return value of True means that there are missing values\n",
    "any(pd.notnull(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Impute feature vectors with the mean of the column values.\n",
    "# H = em.impute_table(H, \n",
    "#                 exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "#                 strategy='mean')\n",
    "\n",
    "H.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a set of ML-matchers\n",
    "dt = em.DTMatcher(name='DecisionTree', random_state=0,max_depth=5)\n",
    "svm = em.SVMMatcher(name='SVM', random_state=0)\n",
    "rf = em.RFMatcher(name='RF', random_state=0)\n",
    "lg = em.LogRegMatcher(name='LogReg', random_state=0)\n",
    "ln = em.LinRegMatcher(name='LinReg')\n",
    "nb = em.NBMatcher(name='NaiveBayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Num folds</th>\n",
       "      <th>Fold 1</th>\n",
       "      <th>Fold 2</th>\n",
       "      <th>Fold 3</th>\n",
       "      <th>Fold 4</th>\n",
       "      <th>Fold 5</th>\n",
       "      <th>Mean score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>&lt;py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x00000250C4581160&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.926108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>&lt;py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x00000250C4581C18&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>&lt;py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x00000250C4581400&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.762289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x00000250C4581978&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.929450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x00000250C4581BE0&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.939540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>&lt;py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x00000250C4581908&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  \\\n",
       "0  DecisionTree   \n",
       "1            RF   \n",
       "2           SVM   \n",
       "3        LinReg   \n",
       "4        LogReg   \n",
       "5    NaiveBayes   \n",
       "\n",
       "                                                                                Matcher  \\\n",
       "0          <py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x00000250C4581160>   \n",
       "1          <py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x00000250C4581C18>   \n",
       "2        <py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x00000250C4581400>   \n",
       "3  <py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x00000250C4581978>   \n",
       "4  <py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x00000250C4581BE0>   \n",
       "5          <py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x00000250C4581908>   \n",
       "\n",
       "   Num folds    Fold 1    Fold 2    Fold 3    Fold 4    Fold 5  Mean score  \n",
       "0          5  0.833333  0.958333  1.000000  0.956522  0.882353    0.926108  \n",
       "1          5  0.888889  0.920000  1.000000  0.958333  1.000000    0.953444  \n",
       "2          5  0.607143  0.821429  0.870968  0.833333  0.678571    0.762289  \n",
       "3          5  0.850000  0.920000  0.964286  0.962963  0.950000    0.929450  \n",
       "4          5  0.850000  0.916667  0.931034  1.000000  1.000000    0.939540  \n",
       "5          5  0.888889  0.920000  0.962963  0.923077  1.000000    0.938986  "
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the best ML matcher using CV\n",
    "result = em.select_matcher([dt, rf, svm, ln, lg, nb], table=H, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        k=5,\n",
    "        target_attr='gold_labels', metric='precision', random_state=0)\n",
    "# result = em.select_matcher([dt, rf, svm, ln, lg, nb], table=H, \n",
    "#         exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "#         k=5,\n",
    "#         target_attr='gold_labels', metric='recall', random_state=0)\n",
    "# result = em.select_matcher([dt, rf, svm, ln, lg, nb], table=H, \n",
    "#         exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "#         k=5,\n",
    "#         target_attr='gold_labels', metric='f1', random_state=0)\n",
    "result['cv_stats']\n",
    "# result['cv_stats'].to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Debug Random Forest\n",
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Debug RF matcher using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        target_attr='gold_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step 4 - removing song_title_song_title_lev_dist, song_title_song_title_nmw and song_title_song_title_sw\n",
    "# AB = AB.drop(AB.index[[5,7,8]])\n",
    "#Step 5 - removing song_title_song_title_cos_dlm_dc0_dlm_dc0, song_title_song_title_mel\n",
    "AB = AB.drop(AB.index[[2,4]])\n",
    "#Step 6 - removing song_title_song_title_jac_dlm_dc0_dlm_dc0, song_title_song_title_lev_sim\n",
    "AB = AB.drop(AB.index[[2,3]])\n",
    "#Step 7 - removing artists_artists_lev_dist, artists_artists_nmw,artists_artists_sw\n",
    "AB = AB.drop(AB.index[[3,4,5,6,8,9]])\n",
    "#Step 8 - removing artists_artists_lev_sim\n",
    "AB = AB.drop(AB.index[[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=AB, \n",
    "                            attrs_after='gold_labels',\n",
    "                            show_progress=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 9 Convert the I into a set of feature vectors using F\n",
    "H['song_title_song_title_jac_qgm_3_qgm_3']\n",
    "H['artists_artists_jac_qgm_3_qgm_3']\n",
    "H['song_title_artists_score']= H.song_title_song_title_jac_qgm_3_qgm_3*H.artists_artists_jac_qgm_3_qgm_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Impute feature vectors with the mean of the column values.\n",
    "# H = em.impute_table(H, \n",
    "#                 exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "#                 strategy='mean')\n",
    "\n",
    "H.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Debug Random Forest\n",
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Debug RF matcher using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        target_attr='gold_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluating matching output\n",
    "#Convert J into a set of feature vectors using feature table\n",
    "L = em.extract_feature_vecs(J, feature_table=AB,\n",
    "                            attrs_after='gold_labels', show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if the feature vectors contain missing values\n",
    "# A return value of True means that there are missing values\n",
    "any(pd.notnull(L))\n",
    "L.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train using feature vectors from I \n",
    "rf.fit(table=H, \n",
    "       exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 3 features per sample; expecting 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-213-0c26cba9521a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;31m# Predict on L\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m predictions = lg.predict(table=L, exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n\u001b[0;32m----> 7\u001b[0;31m                          append=True,target_attr='predicted_labels')\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[1;31m# Evaluate the predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0meval_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_matches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gold_labels'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'predicted_labels'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\py_entitymatching-0.1.0-py3.6.egg\\py_entitymatching\\matcher\\mlmatcher.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, table, exclude_attrs, target_attr, append, inplace)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[1;31m# then call the appropriate predict method.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtable\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mexclude_attrs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_ex_attrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude_attrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[1;31m# If the append is True, update the table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtarget_attr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mappend\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\py_entitymatching-0.1.0-py3.6.egg\\py_entitymatching\\matcher\\mlmatcher.py\u001b[0m in \u001b[0;36m_predict_ex_attrs\u001b[0;34m(self, table, exclude_attrs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[1;31m# Do the predictions using the ML-based matcher.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_sklearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_rem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[1;31m# Finally return the predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\py_entitymatching-0.1.0-py3.6.egg\\py_entitymatching\\matcher\\mlmatcher.py\u001b[0m in \u001b[0;36m_predict_sklearn\u001b[0;34m(self, x, check_rem)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data_for_sklearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_rem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_rem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[1;31m# Call the underlying predict function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[1;31m# Return the predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \"\"\"\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 317\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 3 features per sample; expecting 4"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I \n",
    "lg.fit(table=H, \n",
    "       exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')\n",
    "# Predict on L \n",
    "predictions = lg.predict(table=L, exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "                         append=True,target_attr='predicted_labels')\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'gold_labels', 'predicted_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 17 and input n_features is 18 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-0f1ec507bece>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# Predict on L\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m predictions = rf.predict(table=L, exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n\u001b[0;32m----> 3\u001b[0;31m                          append=True,target_attr='predicted_labels')\n\u001b[0m",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\py_entitymatching-0.1.0-py3.6.egg\\py_entitymatching\\matcher\\mlmatcher.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, table, exclude_attrs, target_attr, append, inplace)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[1;31m# then call the appropriate predict method.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtable\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mexclude_attrs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_ex_attrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude_attrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[1;31m# If the append is True, update the table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtarget_attr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mappend\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\py_entitymatching-0.1.0-py3.6.egg\\py_entitymatching\\matcher\\mlmatcher.py\u001b[0m in \u001b[0;36m_predict_ex_attrs\u001b[0;34m(self, table, exclude_attrs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[1;31m# Do the predictions using the ML-based matcher.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_sklearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_rem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[1;31m# Finally return the predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\py_entitymatching-0.1.0-py3.6.egg\\py_entitymatching\\matcher\\mlmatcher.py\u001b[0m in \u001b[0;36m_predict_sklearn\u001b[0;34m(self, x, check_rem)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data_for_sklearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_rem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_rem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[1;31m# Call the underlying predict function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[1;31m# Return the predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \"\"\"\n\u001b[0;32m--> 534\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \"\"\"\n\u001b[1;32m    572\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    353\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[1;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    374\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 17 and input n_features is 18 "
     ]
    }
   ],
   "source": [
    "# Predict on L \n",
    "predictions = rf.predict(table=L, exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "                         append=True,target_attr='predicted_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 94.55% (104/110)\n",
      "Recall : 90.43% (104/115)\n",
      "F1 : 92.44%\n",
      "False positives : 6 (out of 110 positive predictions)\n",
      "False negatives : 11 (out of 90 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'gold_labels', 'predicted_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
