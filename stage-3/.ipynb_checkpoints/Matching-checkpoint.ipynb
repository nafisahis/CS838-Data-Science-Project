{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import py_entitymatching as em\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets_dir = em.get_install_path() + os.sep + 'datasets'\n",
    "path_A = datasets_dir + os.sep + 'tracks_sample.csv'\n",
    "path_B = datasets_dir + os.sep + 'songs_sample.csv'\n",
    "path_G = datasets_dir + os.sep + 'labeled_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV files\n",
    "A = em.read_csv_metadata(path_A,key='id', low_memory=False) # setting the parameter low_memory to False  to speed up loading.\n",
    "B = em.read_csv_metadata(path_B,key='id',low_memory=False)\n",
    "G = em.read_csv_metadata(path_G,key='id',low_memory=False,ltable=A, rtable=B, \n",
    "                         fk_ltable='ltable_id', fk_rtable='rtable_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split G into I an J\n",
    "train_test = em.split_train_test(G, train_proportion=0.5,random_state=0)\n",
    "I = train_test['train']\n",
    "J = train_test['test']\n",
    "I.to_csv('train.csv')\n",
    "J.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                     id_id_exm\n",
      "1                                     id_id_anm\n",
      "2                                id_id_lev_dist\n",
      "3                                 id_id_lev_sim\n",
      "4                                 year_year_exm\n",
      "5                                 year_year_anm\n",
      "6                            year_year_lev_dist\n",
      "7                             year_year_lev_sim\n",
      "8         song_title_song_title_jac_qgm_3_qgm_3\n",
      "9     song_title_song_title_cos_dlm_dc0_dlm_dc0\n",
      "10    song_title_song_title_jac_dlm_dc0_dlm_dc0\n",
      "11                    song_title_song_title_mel\n",
      "12               song_title_song_title_lev_dist\n",
      "13                song_title_song_title_lev_sim\n",
      "14                    song_title_song_title_nmw\n",
      "15                     song_title_song_title_sw\n",
      "16              artists_artists_jac_qgm_3_qgm_3\n",
      "17          artists_artists_cos_dlm_dc0_dlm_dc0\n",
      "18          artists_artists_jac_dlm_dc0_dlm_dc0\n",
      "19                          artists_artists_mel\n",
      "20                     artists_artists_lev_dist\n",
      "21                      artists_artists_lev_sim\n",
      "22                          artists_artists_nmw\n",
      "23                           artists_artists_sw\n",
      "Name: feature_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Generate a set of features\n",
    "F = em.get_features_for_matching(A, B)\n",
    "print(F.feature_name)\n",
    "# Remove all features on id parameters\n",
    "F = F[4:]\n",
    "# Remove some features on year parameter\n",
    "F = F.drop(F.index[[0,1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert I into a set of feature vectors using F\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F, \n",
    "                            attrs_after='gold_labels',\n",
    "                            show_progress=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the feature vectors contain missing values\n",
    "# A return value of True means that there are missing values\n",
    "any(pd.notnull(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Impute feature vectors with the mean of the column values.\n",
    "H.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a set of ML-matchers\n",
    "dt = em.DTMatcher(name='DecisionTree', random_state=0,max_depth=5)\n",
    "svm = em.SVMMatcher(name='SVM', random_state=0)\n",
    "rf = em.RFMatcher(name='RF', random_state=0)\n",
    "lg = em.LogRegMatcher(name='LogReg', random_state=0)\n",
    "ln = em.LinRegMatcher(name='LinReg')\n",
    "nb = em.NBMatcher(name='NaiveBayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Num folds</th>\n",
       "      <th>Fold 1</th>\n",
       "      <th>Fold 2</th>\n",
       "      <th>Fold 3</th>\n",
       "      <th>Fold 4</th>\n",
       "      <th>Fold 5</th>\n",
       "      <th>Mean score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>&lt;py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x000002DD5ED90208&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.896166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>&lt;py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x000002DD5ED90CF8&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.895608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>&lt;py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x000002DD5ED90E10&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.915285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x000002DD5ED90780&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.917534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x000002DD5ED900F0&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.910091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>&lt;py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x000002DD5ED905F8&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.914674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  \\\n",
       "0  DecisionTree   \n",
       "1            RF   \n",
       "2           SVM   \n",
       "3        LinReg   \n",
       "4        LogReg   \n",
       "5    NaiveBayes   \n",
       "\n",
       "                                                                                Matcher  \\\n",
       "0          <py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x000002DD5ED90208>   \n",
       "1          <py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x000002DD5ED90CF8>   \n",
       "2        <py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x000002DD5ED90E10>   \n",
       "3  <py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x000002DD5ED90780>   \n",
       "4  <py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x000002DD5ED900F0>   \n",
       "5          <py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x000002DD5ED905F8>   \n",
       "\n",
       "   Num folds    Fold 1    Fold 2    Fold 3    Fold 4    Fold 5  Mean score  \n",
       "0          5  0.810811  0.880000  0.981132  0.920000  0.888889    0.896166  \n",
       "1          5  0.864865  0.840000  0.964286  0.920000  0.888889    0.895608  \n",
       "2          5  0.882353  0.893617  0.961538  0.920000  0.918919    0.915285  \n",
       "3          5  0.848485  0.897959  0.981132  0.941176  0.918919    0.917534  \n",
       "4          5  0.833333  0.916667  0.961538  0.920000  0.918919    0.910091  \n",
       "5          5  0.857143  0.875000  0.981132  0.941176  0.918919    0.914674  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute accuracy and select the best ML matcher using CV\n",
    "result_precision = em.select_matcher([dt, rf, svm, ln, lg, nb], table=H, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        k=5,\n",
    "        target_attr='gold_labels', metric='precision', random_state=0)\n",
    "result_recall = em.select_matcher([dt, rf, svm, ln, lg, nb], table=H, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        k=5,\n",
    "        target_attr='gold_labels', metric='recall', random_state=0)\n",
    "result_f1 = em.select_matcher([dt, rf, svm, ln, lg, nb], table=H, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        k=5,\n",
    "        target_attr='gold_labels', metric='f1', random_state=0)\n",
    "result_precision['cv_stats']\n",
    "result_recall['cv_stats']\n",
    "result_f1['cv_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Debug Random Forest Matcher X\n",
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Debug X using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        target_attr='gold_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Debugging iteration 1 - remove song_title_song_title_lev_dist, song_title_song_title_nmw and song_title_song_title_sw,\n",
    "#song_title_song_title_cos_dlm_dc0_dlm_dc0, song_title_song_title_mel,song_title_song_title_jac_dlm_dc0_dlm_dc0\n",
    "F = F.drop(F.index[[2,3,4,5,7,8]])\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F, \n",
    "                            attrs_after='gold_labels',\n",
    "                            show_progress=False) \n",
    "# Impute feature vectors with 0.\n",
    "H.fillna(value=0, inplace=True)\n",
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']\n",
    "# Debug the matcher using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        target_attr='gold_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Debugging iteration 2 - remove song_title_song_title_lev_sim\n",
    "F = F.drop(F.index[[2]])\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F, \n",
    "                            attrs_after='gold_labels',\n",
    "                            show_progress=False) \n",
    "# Impute feature vectors with 0.\n",
    "H.fillna(value=0, inplace=True)\n",
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']\n",
    "# Debug the matcher using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        target_attr='gold_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Debugging iteration 3 - remove artists_artists_lev_dist, artists_artists_nmw,artists_artists_sw\n",
    "F = F.drop(F.index[[3,4,5,6,8,9]])\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F, \n",
    "                            attrs_after='gold_labels',\n",
    "                            show_progress=False) \n",
    "# Impute feature vectors with 0.\n",
    "H.fillna(value=0, inplace=True)\n",
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']\n",
    "# Debug the matcher using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        target_attr='gold_labels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Debugging iteration 4 - remove artists_artists_lev_sim\n",
    "F = F.drop(F.index[[3]])\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F, \n",
    "                            attrs_after='gold_labels',\n",
    "                            show_progress=False) \n",
    "# Impute feature vectors with 0.\n",
    "H.fillna(value=0, inplace=True)\n",
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']\n",
    "# Debug the matcher using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        target_attr='gold_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Debugging iteration 5 - add feature product of jaccard measure on song_title and artists\n",
    "H['song_title_song_title_jac_qgm_3_qgm_3']\n",
    "H['artists_artists_jac_qgm_3_qgm_3']\n",
    "H['song_title_artists_score']= H.song_title_song_title_jac_qgm_3_qgm_3*H.artists_artists_jac_qgm_3_qgm_3\n",
    "# Impute feature vectors with 0.\n",
    "H.fillna(value=0, inplace=True)\n",
    "# Split H into P and Q\n",
    "PQ = em.split_train_test(H, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']\n",
    "# Debug RF matcher using GUI\n",
    "em.vis_debug_rf(rf, P, Q, \n",
    "        exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'],\n",
    "        target_attr='gold_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate matching output\n",
    "# Convert J into a set of feature vectors using feature table\n",
    "L = em.extract_feature_vecs(J, feature_table=F,\n",
    "                            attrs_after='gold_labels', show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if the feature vectors contain missing values\n",
    "# A return value of True means that there are missing values\n",
    "any(pd.notnull(L))\n",
    "L.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train using feature vectors from I using decision tree\n",
    "dt.fit(table=H, \n",
    "       exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')\n",
    "# Predict on L \n",
    "predictions = dt.predict(table=L, exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "                         append=True,target_attr='predicted_labels')\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'gold_labels', 'predicted_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train using feature vectors from I using random forest\n",
    "rf.fit(table=H, \n",
    "       exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')\n",
    "# Predict on L \n",
    "predictions = rf.predict(table=L, exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "                         append=True,target_attr='predicted_labels')\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'gold_labels', 'predicted_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train using feature vectors from I using svm\n",
    "svm.fit(table=H, \n",
    "       exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')\n",
    "# Predict on L \n",
    "predictions = svm.predict(table=L, exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "                         append=True,target_attr='predicted_labels')\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'gold_labels', 'predicted_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train using feature vectors from I using logistic regression\n",
    "lg.fit(table=H, \n",
    "       exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')\n",
    "# Predict on L \n",
    "predictions = lg.predict(table=L, exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "                         append=True,target_attr='predicted_labels')\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'gold_labels', 'predicted_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 94.96% (113/119)\n",
      "Recall : 98.26% (113/115)\n",
      "F1 : 96.58%\n",
      "False positives : 6 (out of 119 positive predictions)\n",
      "False negatives : 2 (out of 81 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I using linear regression\n",
    "ln.fit(table=H, \n",
    "       exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')\n",
    "# Predict on L \n",
    "predictions = ln.predict(table=L, exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "                         append=True,target_attr='predicted_labels')\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'gold_labels', 'predicted_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train using feature vectors from I using naive bayes\n",
    "nb.fit(table=H, \n",
    "       exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "       target_attr='gold_labels')\n",
    "# Predict on L \n",
    "predictions = nb.predict(table=L, exclude_attrs=['id', 'ltable_id', 'rtable_id', 'gold_labels'], \n",
    "                         append=True,target_attr='predicted_labels')\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'gold_labels', 'predicted_labels')\n",
    "em.print_eval_summary(eval_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
